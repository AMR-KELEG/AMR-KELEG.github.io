<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Amr  Keleg | Publications</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="/assets/css/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Amr</span>   Keleg
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/resources/">
                Resources
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching/Services
                
              </a>
          </li>
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">My list of publications in peer-reviewed conferences.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2025</h2>
  <ol class="bibliography"><li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg2025revisitingcommonassumptionsarabic" class="col-sm-8">
    
      <div class="title">Revisiting Common Assumptions about Arabic Dialects in NLP</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  Goldwater, Sharon,
                
              
            
          
        
          
            
              
                
                  and Magdy, Walid
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics</em>
      
      
        2025
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2505.21816" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg2025llmalignmentarabshomogenous" class="col-sm-8">
    
      <div class="title">LLM Alignment for the Arabs: A Homogenous Culture or Diverse Ones?</div>
      <div class="author">
        
          
            
              <em>Keleg, Amr</em>
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 3rd Workshop on Cross-Cultural Considerations in NLP</em>
      
      
        2025
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2503.15003" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      <a href="https://aclanthology.org/2025.c3nlp-1.1/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
      <a href="../../blog/2025/llm_alignment_for_arabs/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Large language models (LLMs) have the potential of being useful tools that can automate tasks and assist humans. However, these models are more fluent in English and more aligned with Western cultures, norms, and values. Arabic-specific LLMs are being developed to better capture the nuances of the Arabic language, as well as the views of the Arabs. Yet, Arabs are sometimes assumed to share the same culture. In this position paper, I discuss the limitations of this assumption and provide preliminary thoughts for how to build systems that can better represent the cultural diversity within the Arab world. The invalidity of the cultural homogeneity assumption might seem obvious, yet, it is widely adopted in developing multilingual and Arabic-specific LLMs. I hope that this paper will encourage the NLP community to be considerate of the cultural diversity within various communities speaking the same language.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-etal-2024-estimating" class="col-sm-8">
    
      <div class="title">Estimating the Level of Dialectness Predicts Inter-annotator Agreement in Multi-dialect Arabic Datasets</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  Magdy, Walid,
                
              
            
          
        
          
            
              
                
                  and Goldwater, Sharon
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>
      
      
        2024
      
      </div>
    

    <div class="periodical">
      
      <u style="color:red;">ACL 2024 Outstanding Paper Award</u>
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://aclanthology.org/2024.acl-short.69" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
      <a href="https://github.com/AMR-KELEG/ALDi-and-IAA" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>On annotating multi-dialect Arabic datasets, it is common to randomly assign the samples across a pool of native Arabic speakers. Recent analyses recommended routing dialectal samples to native speakers of their respective dialects to build higher-quality datasets. However, automatically identifying the dialect of samples is hard. Moreover, the pool of annotators who are native speakers of specific Arabic dialects might be scarce. Arabic Level of Dialectness (ALDi) was recently introduced as a quantitative variable that measures how sentences diverge from Standard Arabic. On randomly assigning samples to annotators, we hypothesize that samples of higher ALDi scores are harder to label especially if they are written in dialects that the annotators do not speak. We test this by analyzing the relation between ALDi scores and the annotators’ agreement, on 15 public datasets having raw individual sample annotations for various sentence-classification tasks. We find strong evidence supporting our hypothesis for 11 of them. Consequently, we recommend prioritizing routing samples of high ALDi scores to native speakers of each sample’s dialect, for which the dialect could be automatically identified at higher accuracies.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="abdul-mageed-etal-2024-nadi" class="col-sm-8">
    
      <div class="title">NADI 2024: The Fifth Nuanced Arabic Dialect Identification Shared Task</div>
      <div class="author">
        
          
            
              
                
                  Abdul-Mageed, Muhammad,
                
              
            
          
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  Elmadany, AbdelRahim,
                
              
            
          
        
          
            
              
                
                  Zhang, Chiyu,
                
              
            
          
        
          
            
              
                
                  Hamed, Injy,
                
              
            
          
        
          
            
              
                
                  Magdy, Walid,
                
              
            
          
        
          
            
              
                
                  Bouamor, Houda,
                
              
            
          
        
          
            
              
                
                  and Habash, Nizar
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of The Second Arabic Natural Language Processing Conference</em>
      
      
        2024
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://aclanthology.org/2024.arabicnlp-1.79" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
      <a href="https://huggingface.co/spaces/AMR-KELEG/MLADI" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We describe the findings of the fifth Nuanced Arabic Dialect Identification Shared Task (NADI 2024). NADI’s objective is to help advance SoTA Arabic NLP by providing guidance, datasets, modeling opportunities, and standardized evaluation conditions that allow researchers to collaboratively compete on prespecified tasks. NADI 2024 targeted both dialect identification cast as a multi-label task (Subtask 1), identification of the Arabic level of dialectness (Subtask 2), and dialect-to-MSA machine translation (Subtask 3). A total of 51 unique teams registered for the shared task, of whom 12 teams have participated (with 76 valid submissions during the test phase). Among these, three teams participated in Subtask 1, three in Subtask 2, and eight in Subtask 3. The winning teams achieved 50.57 F1 on Subtask 1, 0.1403 RMSE for Subtask 2, and 20.44 BLEU in Subtask 3, respectively. Results show that Arabic dialect processing tasks such as dialect identification and machine translation remain challenging. We describe the methods employed by the participating teams and briefly offer an outlook for NADI.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-etal-2023-aldi" class="col-sm-8">
    
      <div class="title">ALDi: Quantifying the Arabic Level of Dialectness of Text</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  Goldwater, Sharon,
                
              
            
          
        
          
            
              
                
                  and Magdy, Walid
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>
      
      
        2023
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2310.13747" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      <a href="https://aclanthology.org/2023.emnlp-main.655" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
      <a href="https://github.com/AMR-KELEG/ALDi" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="/assets/pdf/ALDi_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
      <a href="https://huggingface.co/spaces/AMR-KELEG/ALDi" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Transcribed speech and user-generated text in Arabic typically contain a mixture of Modern Standard Arabic (MSA), the standardized language taught in schools, and Dialectal Arabic (DA), used in daily communications. To handle this variation, previous work in Arabic NLP has focused on Dialect Identification (DI) on the sentence or the token level. However, DI treats the task as binary, whereas we argue that Arabic speakers perceive a spectrum of dialectness, which we operationalize at the sentence level as the Arabic Level of Dialectness (ALDi), a continuous linguistic variable. We introduce the AOC-ALDi dataset (derived from the AOC dataset), containing 127,835 sentences (17% from news articles and 83% from user comments on those articles) which are manually labeled with their level of dialectness. We provide a detailed analysis of AOC-ALDi and show that a model trained on it can effectively identify levels of dialectness on a range of other corpora (including dialects and genres not included in AOC-ALDi), providing a more nuanced picture than traditional DI systems. Through case studies, we illustrate how ALDi can reveal Arabic speakers’ stylistic choices in different situations, a useful property for sociolinguistic analyses.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-magdy-2023-arabic" class="col-sm-8">
    
      <div class="title">Arabic Dialect Identification under Scrutiny: Limitations of Single-label Classification</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  and Magdy, Walid
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of ArabicNLP 2023</em>
      
      
        2023
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2310.13661" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
      <a href="https://aclanthology.org/2023.arabicnlp-1.31" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
      <a href="https://github.com/AMR-KELEG/ADI-under-scrutiny" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Automatic Arabic Dialect Identification (ADI) of text has gained great popularity since it was introduced in the early 2010s. Multiple datasets were developed, and yearly shared tasks have been running since 2018. However, ADI systems are reported to fail in distinguishing between the micro-dialects of Arabic. We argue that the currently adopted framing of the ADI task as a single-label classification problem is one of the main reasons for that. We highlight the limitation of the incompleteness of the Dialect labels and demonstrate how it impacts the evaluation of ADI systems. A manual error analysis for the predictions of an ADI, performed by 7 native speakers of different Arabic dialects, revealed that ≈67% of the validated errors are not true errors. Consequently, we propose framing ADI as a multi-label classification task and give recommendations for designing new ADI datasets.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-magdy-2023-dlama" class="col-sm-8">
    
      <div class="title">DLAMA: A Framework for Curating Culturally Diverse Facts for Probing the Knowledge of Pretrained Language Models</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  and Magdy, Walid
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Findings of the Association for Computational Linguistics: ACL 2023</em>
      
      
        2023
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://aclanthology.org/2023.findings-acl.389" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
      <a href="https://github.com/AMR-KELEG/DLAMA" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      
      <a href="/assets/pdf/DLAMA_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/DLAMA_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A few benchmarking datasets have been released to evaluate the factual knowledge of pretrained language models. These benchmarks (e.g., LAMA, and ParaRel) are mainly developed in English and later are translated to form new multilingual versions (e.g., mLAMA, and mParaRel). Results on these multilingual benchmarks suggest that using English prompts to recall the facts from multilingual models usually yields significantly better and more consistent performance than using non-English prompts. Our analysis shows that mLAMA is biased toward facts from Western countries, which might affect the fairness of probing models. We propose a new framework for curating factual triples from Wikidata that are culturally diverse. A new benchmark DLAMA-v1 is built of factual triples from three pairs of contrasting cultures having a total of 78,259 triples from 20 relation predicates. The three pairs comprise facts representing the (Arab and Western), (Asian and Western), and (South American and Western) countries respectively. Having a more balanced benchmark (DLAMA-v1) supports that mBERT performs better on Western facts than non-Western ones, while monolingual Arabic, English, and Korean models tend to perform better on their culturally proximate facts. Moreover, both monolingual and multilingual models tend to make a prediction that is culturally or geographically relevant to the correct label, even if the prediction is wrong.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-magdy-2022-smash" class="col-sm-8">
    
      <div class="title">SMASH at Qur’an QA 2022: Creating Better Faithful Data 
Splits for Low-resourced Question Answering Scenarios</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  and Magdy, Walid
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 5th Workshop on Open-Source Arabic 
Corpora and Processing Tools with Shared Tasks on Qur’an QA and 
Fine-Grained Hate Speech Detection</em>
      
      
        2022
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://aclanthology.org/2022.osact-1.17" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/smash_QA_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The Qur’an QA 2022 shared task aims at assessing the 
possibility of building systems that can extract answers to religious 
questions given relevant passages from the Holy Qur’an. This paper 
describes SMASH’s system that was used to participate in this shared 
task. Our experiments reveal a data leakage issue among the different 
splits of the dataset. This leakage problem hinders the reliability of 
using the models’ performance on the development dataset as a proxy for 
the ability of the models to generalize to new unseen samples. After 
creating better faithful splits from the original dataset, the basic 
strategy of fine-tuning a language model pretrained on classical Arabic 
text yielded the best performance on the new evaluation split. The results 
achieved by the model suggests that the small scale dataset is not enough 
to fine-tune large transformer-based language models in a way that 
generalizes well. Conversely, we believe that further attention could be 
paid to the type of questions that are being used to train the models 
given the sensitivity of the data.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-etal-2022-automatically" class="col-sm-8">
    
      <div class="title">Automatically Discarding Straplines to Improve Data Quality for Abstractive News Summarization</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  Lindemann, Matthias,
                
              
            
          
        
          
            
              
                
                  Liu, Danyang,
                
              
            
          
        
          
            
              
                
                  Long, Wanqiu,
                
              
            
          
        
          
            
              
                
                  and Webber, Bonnie L.
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of NLP Power! The First Workshop on Efficient Benchmarking in NLP</em>
      
      
        2022
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://aclanthology.org/2022.nlppower-1.5" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent improvements in automatic news summarization fundamentally rely on large corpora of news articles and their 
summaries. These corpora are often constructed by scraping news websites, which results in including not only summaries but also other 
kinds of texts. Apart from more generic noise, we identify straplines as a form of text scraped from news websites that commonly turn out 
not to be summaries. The presence of these non-summaries threatens the validity of scraped corpora as benchmarks for news summarization. 
We have annotated extracts from two news sources that form part of the Newsroom corpus (Grusky et al., 2018), labeling those which were 
straplines, those which were summaries, and those which were both. We present a rule-based strapline detection method that achieves good 
performance on a manually annotated test set. Automatic evaluation indicates that removing straplines and noise from the training data of 
a news summarizer results in higher quality summaries, with improvements as high as 7 points ROUGE score.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-etal-2020-unsupervised" class="col-sm-8">
    
      <div class="title">An Unsupervised Method for Weighting Finite-state Morphological Analyzers</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  Tyers, Francis,
                
              
            
          
        
          
            
              
                
                  Howell, Nick,
                
              
            
          
        
          
            
              
                
                  and Pirinen, Tommi
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 12th Language Resources and Evaluation Conference</em>
      
      
        2020
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.aclweb.org/anthology/2020.lrec-1.474/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Morphological analysis is one of the tasks that have been studied for years. Different techniques have been used to develop models for performing morphological analysis. Models based on finite state transducers have proved to be more suitable for languages with low available resources. In this paper, we have developed a method for weighting a morphological analyzer built using finite state transducers in order to disambiguate its results. The method is based on a word2vec model that is trained in a completely unsupervised way using raw untagged corpora and is able to capture the semantic meaning of the words. Most of the methods used for disambiguating the results of a morphological analyzer relied on having tagged corpora that need to manually built. Additionally, the method developed uses information about the token irrespective of its context unlike most of the other techniques that heavily rely on the word’s context to disambiguate its set of candidate analyses.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">

  <div class="col-sm-2 abbr">
  
  </div>

  <div id="keleg-etal-2020-asu" class="col-sm-8">
    
      <div class="title">ASU_OPTO at OSACT4 - Offensive Language Detection for Arabic text</div>
      <div class="author">
        
          
            
              
                <em>Keleg, Amr</em>,
              
            
          
        
          
            
              
                
                  El-Beltagy, Samhaa R.,
                
              
            
          
        
          
            
              
                
                  and Khalil, Mahmoud
                
              
            
          
        
      </div>


        <div class="periodical">
        
        <em>In Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</em>
      
      
        2020
      
      </div>
    

    <div class="periodical">
      
    </div>


    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://www.aclweb.org/anthology/2020.osact-1.10/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage. Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays. In this paper, we describe the model that was submitted to the Shared Task on Offensive Language Detection that is organized by (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Our model makes use transformer based model (BERT) to detect offensive content. We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Amr  Keleg.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
    Last updated: July 20, 2025.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TTZJTTPT6P"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-TTZJTTPT6P');
</script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
