---
---


@inproceedings{keleg2022smash,
  selected={true},
  title={SMASH at Qurâ€™an QA 2022: Creating Better Faithful Data Splits for Low-resourced Question Answering Scenarios},
  author={Keleg, Amr and Magdy, Walid},
  booktitle={Proceedings of the 5th Workshop on Open-Source Arabic Corpora and Processing Tools (OSACT5) at the 13th Language Resources and Evaluation Conference (LREC 2022)},
  year={2022}
}

@inproceedings{keleg-etal-2022-automatically,
    selected={true},
    title = "Automatically Discarding Straplines to Improve Data Quality for Abstractive News Summarization",
    author = "Keleg, Amr  and
      Lindemann, Matthias  and
      Liu, Danyang  and
      Long, Wanqiu  and
      Webber, Bonnie L.",
    booktitle = "Proceedings of NLP Power! The First Workshop on Efficient Benchmarking in NLP",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.nlppower-1.5",
    html = "https://aclanthology.org/2022.nlppower-1.5",
    pages = "42--51",
    abstract = "Recent improvements in automatic news summarization fundamentally rely on large corpora of news articles and their 
summaries. These corpora are often constructed by scraping news websites, which results in including not only summaries but also other 
kinds of texts. Apart from more generic noise, we identify straplines as a form of text scraped from news websites that commonly turn out 
not to be summaries. The presence of these non-summaries threatens the validity of scraped corpora as benchmarks for news summarization. 
We have annotated extracts from two news sources that form part of the Newsroom corpus (Grusky et al., 2018), labeling those which were 
straplines, those which were summaries, and those which were both. We present a rule-based strapline detection method that achieves good 
performance on a manually annotated test set. Automatic evaluation indicates that removing straplines and noise from the training data of 
a news summarizer results in higher quality summaries, with improvements as high as 7 points ROUGE score.",
}


@inproceedings{keleg-etal-2020-unsupervised,
    selected={false},
    title = "An Unsupervised Method for Weighting Finite-state Morphological Analyzers",
    author = "Keleg, Amr  and
      Tyers, Francis  and
      Howell, Nick  and
      Pirinen, Tommi",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.474",
    html = "https://www.aclweb.org/anthology/2020.lrec-1.474/",
    pages = "3842--3850",
    abstract = "Morphological analysis is one of the tasks that have been studied for years. Different techniques have been used to develop models for performing morphological analysis. Models based on finite state transducers have proved to be more suitable for languages with low available resources. In this paper, we have developed a method for weighting a morphological analyzer built using finite state transducers in order to disambiguate its results. The method is based on a word2vec model that is trained in a completely unsupervised way using raw untagged corpora and is able to capture the semantic meaning of the words. Most of the methods used for disambiguating the results of a morphological analyzer relied on having tagged corpora that need to manually built. Additionally, the method developed uses information about the token irrespective of its context unlike most of the other techniques that heavily rely on the word{'}s context to disambiguate its set of candidate analyses.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{keleg-etal-2020-asu,
    selected={true},
    title = "{ASU}{\_}{OPTO} at {OSACT}4 - Offensive Language Detection for {A}rabic text",
    author = "Keleg, Amr  and
      El-Beltagy, Samhaa R.  and
      Khalil, Mahmoud",
    booktitle = "Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resource Association",
    url = "https://www.aclweb.org/anthology/2020.osact-1.10",
    html= "https://www.aclweb.org/anthology/2020.osact-1.10/",
    pages = "66--70",
    abstract = "In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage. Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays. In this paper, we describe the model that was submitted to the Shared Task on Offensive Language Detection that is organized by (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Our model makes use transformer based model (BERT) to detect offensive content. We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).",
    language = "English",
    ISBN = "979-10-95546-51-1",
}
